{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Download MNIST dataset\n",
    "emnist_train = torchvision.datasets.EMNIST('./dataset/', download=True, train=True, split='digits')\n",
    "emnist_eval = torchvision.datasets.EMNIST('./dataset', download=True, train=False, split='digits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data in a matrix of form [batch, dim]\n",
    "# Create list of correct_labels for train and eval sets\n",
    "\n",
    "dim = 28*28\n",
    "\n",
    "n_images_train = 1000 # len(emnist_train))\n",
    "n_images_eval = 10 # len(emnist_eval))\n",
    "\n",
    "train_data = np.empty([n_images_train, dim])\n",
    "train_correct_labels = []\n",
    "\n",
    "eval_data = np.empty([n_images_eval, dim])\n",
    "eval_correct_labels = []\n",
    "\n",
    "for i in range(n_images_train):\n",
    "    train_data[i] = np.array(emnist_train[i][0]).reshape(1, dim)\n",
    "    train_correct_labels.append(emnist_train[i][1])\n",
    "\n",
    "for i in range(n_images_eval):\n",
    "    eval_data[i] = np.array(emnist_eval[i][0]).reshape(1, dim)\n",
    "    eval_correct_labels.append(emnist_eval[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.VectorSpace import VectorSpace\n",
    "from src.VectorSet import VectorSet\n",
    "\n",
    "def cossine_similarity(vector:np.ndarray, subspace:VectorSpace) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns S = \\sum_{i=0}^{r-1} \\frac{(x,\\phi_i)^2}{\\|x\\|\\|\\phi_i\\|}\n",
    "    \"\"\"\n",
    "    if vector.ndim > 2:\n",
    "        raise(AssertionError(\"Cannot input tensor of ndim > 2\"))\n",
    "    if vector.ndim == 1:\n",
    "        vector = vector[np.newaxis, :]\n",
    "    if vector.shape[1] != subspace.dim:\n",
    "        raise(AssertionError(\"Vector dimension must be the same as VectorSpace dimension\"))       \n",
    "\n",
    "    vector = vector.astype(subspace.dtype)\n",
    "\n",
    "    S = np.sum(\n",
    "            np.divide(\n",
    "                np.matmul(vector, subspace.A.transpose())**2,\n",
    "                np.matmul(\n",
    "                    np.sqrt(\n",
    "                        np.diag(\n",
    "                            np.matmul(vector, vector.transpose()\n",
    "                            )\n",
    "                        )\n",
    "                    )[np.newaxis, :].transpose(),\n",
    "                    np.sqrt(\n",
    "                        np.diag(\n",
    "                            np.matmul(subspace.A, subspace.A.transpose())\n",
    "                        )\n",
    "                    )[np.newaxis, :]\n",
    "                )\n",
    "            ), axis=1\n",
    "        )\n",
    "    return S\n",
    "\n",
    "def scaled_cossine_similarity(vector:np.ndarray, subspace:VectorSpace) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns S = \\sum_{i=0}^{r-1} \\sigma_i \\frac{(x,\\phi_i)^2}{\\|x\\|\\|\\phi_i\\|}\n",
    "    \"\"\"\n",
    "    if vector.ndim > 2:\n",
    "        raise(AssertionError(\"Cannot input tensor of ndim > 2\"))\n",
    "    if vector.ndim == 1:\n",
    "        vector = vector[np.newaxis, :]\n",
    "    if vector.shape[1] != subspace.dim:\n",
    "        raise(AssertionError(\"Vector dimension must be the same as VectorSpace dimension\"))       \n",
    "\n",
    "    vector = vector.astype(subspace.dtype)\n",
    "\n",
    "    S = np.inner(\n",
    "            np.divide(\n",
    "                np.matmul(vector, subspace.A.transpose())**2,\n",
    "                np.matmul(\n",
    "                    np.sqrt(\n",
    "                        np.diag(\n",
    "                            np.matmul(vector, vector.transpose()\n",
    "                            )\n",
    "                        )\n",
    "                    )[np.newaxis, :].transpose(),\n",
    "                    np.sqrt(\n",
    "                        np.diag(\n",
    "                            np.matmul(subspace.A, subspace.A.transpose())\n",
    "                        )\n",
    "                    )[np.newaxis, :]\n",
    "                )\n",
    "            ),\n",
    "            np.array(subspace.singular_values, dtype=subspace.dtype)\n",
    "        )\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94404213e4c4fc68b3c6a276caf1e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.7\n",
      "0.7 0.7\n",
      "0.7 0.7\n",
      "0.8 0.8\n",
      "0.8 0.8\n",
      "0.8 0.8\n",
      "0.8 0.8\n",
      "0.8 0.8\n",
      "0.8 0.8\n",
      "1.0 1.0\n",
      "1.0 1.0\n",
      "1.0 1.0\n",
      "1.0 1.0\n",
      "1.0 1.0\n",
      "0.9 0.9\n",
      "0.9 0.9\n",
      "0.9 0.9\n",
      "0.9 0.9\n",
      "0.9 0.9\n",
      "0.9 0.9\n",
      "0.9 0.9\n"
     ]
    }
   ],
   "source": [
    "# List of min energy for parameter tunning\n",
    "min_energy_list = np.linspace(0.05, 1, 21)\n",
    "\n",
    "# Create a VectorSet for all VectorSpaces\n",
    "set = VectorSet(dim=dim)\n",
    "set.populate(train_data, train_correct_labels)\n",
    "\n",
    "for min_energy in tqdm(min_energy_list):\n",
    "    # Generate Subspaces using pca (svd) and maintain the N biggest eigenvectors, energy(N) > energy(min_energy)\n",
    "    subset = set.pca(min_energy=min_energy)\n",
    "\n",
    "    # Create a list of max likelihood using the traditional cossine similarity and the scaled cossine similarity\n",
    "    max_likelihood_cs = [None]*eval_data.shape[0]\n",
    "    cs_list = [0]*eval_data.shape[0]\n",
    "    \n",
    "    max_likelihood_scs = [None]*eval_data.shape[0]\n",
    "    scs_list = [0]*eval_data.shape[0]\n",
    "\n",
    "    # Classify the eval_data\n",
    "    for subspace in subset:\n",
    "        cs = cossine_similarity(eval_data, subspace)\n",
    "        scs = scaled_cossine_similarity(eval_data, subspace)\n",
    "        for i in range(len(cs)):\n",
    "            if cs[i] > cs_list[i]: cs_list[i] = cs[i]; max_likelihood_cs[i] = subspace.label\n",
    "            if scs[i] > scs_list[i]: scs_list[i] = scs[i]; max_likelihood_scs[i] = subspace.label\n",
    "\n",
    "    correct_class_cs = []\n",
    "    correct_class_scs = []\n",
    "    for l1, l2 in zip(max_likelihood_cs, eval_correct_labels):\n",
    "        correct_class_cs.append(l1 == l2)\n",
    "    for l1, l2 in zip(max_likelihood_scs, eval_correct_labels):\n",
    "        correct_class_scs.append(l1 == l2)\n",
    "\n",
    "    prediction_ratio_cs = correct_class_cs.count(True) / len(correct_class_cs)\n",
    "    prediction_ratio_scs = correct_class_scs.count(True) / len(correct_class_scs)\n",
    "\n",
    "    print(prediction_ratio_cs, prediction_ratio_scs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(subset[0].singular_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
